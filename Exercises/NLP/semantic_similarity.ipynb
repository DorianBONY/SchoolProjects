{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sentence_transformers'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-fbabc531d2a3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m#pip install sentence-transformers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msentence_transformers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutil\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sentence_transformers'"
     ]
    }
   ],
   "source": [
    "#pip install sentence-transformers\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of models optimized for semantic textual similarity can be found at:\n",
    "# https://docs.google.com/spreadsheets/d/14QplCdTCDwEmTqrn1LH4yrbKvdogK4oQvYO1K1aPR5M/edit#gid=0\n",
    "model = SentenceTransformer('stsb-roberta-large')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate semantic similarity between two sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: I like Python because I can build AI applications\n",
      "Sentence 2: I like Python because I can do data analytics\n",
      "Similarity score: 0.8015280961990356\n"
     ]
    }
   ],
   "source": [
    "sentence1 = \"I like Python because I can build AI applications\"\n",
    "sentence2 = \"I like Python because I can do data analytics\"\n",
    "\n",
    "# encode sentences to get their embeddings\n",
    "embedding1 = model.encode(sentence1, convert_to_tensor=True)\n",
    "embedding2 = model.encode(sentence2, convert_to_tensor=True)\n",
    "\n",
    "# compute similarity scores of two embeddings\n",
    "cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "\n",
    "print(\"Sentence 1:\", sentence1)\n",
    "print(\"Sentence 2:\", sentence2)\n",
    "print(\"Similarity score:\", cosine_scores.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate semantic similarity between two lists of sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence 1: I like Python because I can build AI applications\n",
      "Sentence 2: I like Python because I can do data analytics\n",
      "Similarity Score: 0.8015284538269043\n",
      "\n",
      "Sentence 1: I like Python because I can build AI applications\n",
      "Sentence 2: The cat walks on the sidewalk\n",
      "Similarity Score: -0.03110978752374649\n",
      "\n",
      "Sentence 1: I like Python because I can build AI applications\n",
      "Sentence 2: This is a picture of a favorite place on Mount Koya, near Kobe\n",
      "Similarity Score: 0.3189034163951874\n",
      "\n",
      "Sentence 1: The cat sits on the ground\n",
      "Sentence 2: I like Python because I can do data analytics\n",
      "Similarity Score: 0.11328648030757904\n",
      "\n",
      "Sentence 1: The cat sits on the ground\n",
      "Sentence 2: The cat walks on the sidewalk\n",
      "Similarity Score: 0.40381497144699097\n",
      "\n",
      "Sentence 1: The cat sits on the ground\n",
      "Sentence 2: This is a picture of a favorite place on Mount Koya, near Kobe\n",
      "Similarity Score: 0.11604969948530197\n",
      "\n",
      "Sentence 1: I always wanted to go to Japan, but I never had a chance.  Finally I went to Kyoto\n",
      "Sentence 2: I like Python because I can do data analytics\n",
      "Similarity Score: 0.2131677269935608\n",
      "\n",
      "Sentence 1: I always wanted to go to Japan, but I never had a chance.  Finally I went to Kyoto\n",
      "Sentence 2: The cat walks on the sidewalk\n",
      "Similarity Score: 0.07459670305252075\n",
      "\n",
      "Sentence 1: I always wanted to go to Japan, but I never had a chance.  Finally I went to Kyoto\n",
      "Sentence 2: This is a picture of a favorite place on Mount Koya, near Kobe\n",
      "Similarity Score: 0.38108697533607483\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sentences1 = [\"I like Python because I can build AI applications\", \"The cat sits on the ground\",\"I always wanted to go to Japan, but I never had a chance.  Finally I went to Kyoto\"]   \n",
    "sentences2 = [\"I like Python because I can do data analytics\", \"The cat walks on the sidewalk\",\"This is a picture of a favorite place on Mount Koya, near Kobe\"]\n",
    "\n",
    "# encode list of sentences to get their embeddings\n",
    "embedding1 = model.encode(sentences1, convert_to_tensor=True)\n",
    "embedding2 = model.encode(sentences2, convert_to_tensor=True)\n",
    "\n",
    "# compute similarity scores of two embeddings\n",
    "cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n",
    "\n",
    "for i in range(len(sentences1)):\n",
    "    for j in range(len(sentences2)):\n",
    "        print(\"Sentence 1:\", sentences1[i])\n",
    "        print(\"Sentence 2:\", sentences2[j])\n",
    "        print(\"Similarity Score:\", cosine_scores[i][j].item())\n",
    "        print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Top K most similar sentences from a corpus given a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [\"I like Python because I can build AI applications\",\n",
    "          \"I like Python because I can do data analytics\",\n",
    "          \"The cat sits on the ground\",\n",
    "         \"The cat walks on the sidewalk\",\n",
    "         \"I always wanted to go to Japan, but I never had a chance.  Finally I went to Kyoto\",\n",
    "         \"This is a picture of a favorite place on Mount Koya, near Kobe\"]\n",
    "\n",
    "# encode corpus to get corpus embeddings\n",
    "corpus_embeddings = model.encode(corpus, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"Saicho went to Mount Hiei near Kyoto\"\n",
    "\n",
    "# encode sentence to get sentence embeddings\n",
    "sentence_embedding = model.encode(sentence, convert_to_tensor=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence: Saicho went to Mount Hiei near Kyoto \n",
      "\n",
      "Top 2 most similar sentences in corpus:\n",
      "This is a picture of a favorite place on Mount Koya, near Kobe (Score: 0.3764)\n",
      "I always wanted to go to Japan, but I never had a chance.  Finally I went to Kyoto (Score: 0.2940)\n"
     ]
    }
   ],
   "source": [
    "# top_k results to return\n",
    "top_k=2\n",
    "\n",
    "# compute similarity scores of the sentence with the corpus\n",
    "cos_scores = util.pytorch_cos_sim(sentence_embedding, corpus_embeddings)[0]\n",
    "\n",
    "# Sort the results in decreasing order and get the first top_k\n",
    "top_results = np.argpartition(-cos_scores, range(top_k))[0:top_k]\n",
    "\n",
    "print(\"Sentence:\", sentence, \"\\n\")\n",
    "print(\"Top\", top_k, \"most similar sentences in corpus:\")\n",
    "for idx in top_results[0:top_k]:\n",
    "    print(corpus[idx], \"(Score: %.4f)\" % (cos_scores[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
